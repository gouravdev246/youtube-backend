// const { OpenAI } = require('openai');
// // 1. Initialize the client using your Nebius credentials
// const client = new OpenAI({
//     baseURL: 'https://api.tokenfactory.nebius.com/v1/',
//     apiKey: process.env.OPENAI_API_KEY,
// });

// /**
//  * Sends the filtered comments and user question to the Meta Llama AI for analysis.
//  * @param {Array<string>} cleanComments - The filtered array of comments.
//  * @param {string} userQuestion - The question asked by the user.
//  * @returns {Promise<string>} - The AI's generated text answer.
//  */
// const analyzeCommentsWithAI = async (cleanComments, userQuestion) => {
//     try {
//         // Convert the array of comments into a single string for the prompt
//         const commentsText = cleanComments.join('\n- ');

//         // Build the System Prompt
//         // Build the System Prompt (Strict Instructions for Short Answers)
//         const systemPrompt = `You are a precise and highly direct YouTube video analyzer. 
//         Here are the top comments from a YouTube video:

//         ${commentsText}

//         Strict Instructions:
//         1. Answer the user's question directly and concisely.
//         2. DO NOT use filler phrases like "Based on the comments", "It seems that", or "Overall". Start your answer immediately with the main point.
//         3. Keep your answer extremely short (Maximum 2 to 3 sentences).
//         4. Summarize the overall sentiment. DO NOT quote long comments verbatim.
//         5. Give a definitive answer (e.g., Yes, this is good for beginners) right at the beginning.
//         6. If the comments lack the information to answer, reply exactly with: "The comments do not provide enough information to answer this."`;

//         // 2. Call the AI using your specific snippet structure
//         const response = await client.chat.completions.create({
//             model: "meta-llama/Meta-Llama-3.1-8B-Instruct",
//             messages: [
//                 {
//                     role: "system",
//                     content: systemPrompt
//                 },
//                 {
//                     role: "user",
//                     content: [
//                         {
//                             type: "text",
//                             text: userQuestion
//                         }
//                     ]
//                 }
//             ],
//             temperature: 0.3 // Keeps the AI focused and analytical
//         });

//         // 3. Return the text generated by the Llama model
//         return response.choices[0].message.content;

//     } catch (error) {
//         console.error("AI API Error:", error.message);
//         throw new Error("The AI failed to analyze the comments. Please try again.");
//     }
// };

// module.exports = { analyzeCommentsWithAI };





const { OpenAI } = require('openai');

const client = new OpenAI({
    baseURL: 'https://api.tokenfactory.nebius.com/v1/',
    apiKey: process.env.OPENAI_API_KEY,
});

// Function 1: The Heavy Lifter (Runs ONCE)
const generateMasterSummary = async (cleanComments) => {
    const commentsText = cleanComments.join('\n- ');
    const systemPrompt = `You are an expert data analyst. Read the following YouTube comments and write a highly detailed, comprehensive master report. Include overall sentiment, main praises, criticisms, common questions, and specific timestamps mentioned. Leave no technical detail out. \n\nComments:\n${commentsText}`;

    const response = await client.chat.completions.create({
        model: "deepseek-ai/DeepSeek-V3.2", // The BIG model
        messages: [{ role: "user", content: systemPrompt }],
        temperature: 0.2
    });
    return response.choices[0].message.content;
};

// Function 2: The Fast Chatter (Runs EVERY TIME) â€” streams the response
const answerFromSummary = async (masterSummary, userQuestion) => {
    const systemPrompt = `You are a direct YouTube comment analyst. Use the report below to answer the user's question.

Report:
${masterSummary}

Rules:
- Answer in plain text only. No markdown, no bullet points, no bold (**text**), no headers.
- Maximum 3 short sentences.
- Start directly with the answer. No filler phrases like "Based on the report" or "According to comments".
- If the report doesn't contain enough information, just say: "The comments don't have enough info to answer this."`;

    const stream = await client.chat.completions.create({
        model: "meta-llama/Meta-Llama-3.1-8B-Instruct",
        messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: userQuestion }
        ],
        temperature: 0.2,
        stream: true   // Enable streaming
    });
    return stream;  // Return the stream object, controller will handle it
};

module.exports = { generateMasterSummary, answerFromSummary };