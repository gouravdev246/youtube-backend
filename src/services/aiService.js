const { OpenAI } = require('openai');
// 1. Initialize the client using your Nebius credentials
const client = new OpenAI({
    baseURL: 'https://api.tokenfactory.nebius.com/v1/',
    apiKey: process.env.OPENAI_API_KEY,
});

/**
 * Sends the filtered comments and user question to the Meta Llama AI for analysis.
 * @param {Array<string>} cleanComments - The filtered array of comments.
 * @param {string} userQuestion - The question asked by the user.
 * @returns {Promise<string>} - The AI's generated text answer.
 */
const analyzeCommentsWithAI = async (cleanComments, userQuestion) => {
    try {
        // Convert the array of comments into a single string for the prompt
        const commentsText = cleanComments.join('\n- ');

        // Build the System Prompt
        // Build the System Prompt (Strict Instructions for Short Answers)
        const systemPrompt = `You are a precise and highly direct YouTube video analyzer. 
        Here are the top comments from a YouTube video:
        
        ${commentsText}
        
        Strict Instructions:
        1. Answer the user's question directly and concisely.
        2. DO NOT use filler phrases like "Based on the comments", "It seems that", or "Overall". Start your answer immediately with the main point.
        3. Keep your answer extremely short (Maximum 2 to 3 sentences).
        4. Summarize the overall sentiment. DO NOT quote long comments verbatim.
        5. Give a definitive answer (e.g., Yes, this is good for beginners) right at the beginning.
        6. If the comments lack the information to answer, reply exactly with: "The comments do not provide enough information to answer this."`;

        // 2. Call the AI using your specific snippet structure
        const response = await client.chat.completions.create({
            model: "meta-llama/Meta-Llama-3.1-8B-Instruct",
            messages: [
                {
                    role: "system",
                    content: systemPrompt
                },
                {
                    role: "user",
                    content: [
                        {
                            type: "text",
                            text: userQuestion
                        }
                    ]
                }
            ],
            temperature: 0.3 // Keeps the AI focused and analytical
        });

        // 3. Return the text generated by the Llama model
        return response.choices[0].message.content;

    } catch (error) {
        console.error("AI API Error:", error.message);
        throw new Error("The AI failed to analyze the comments. Please try again.");
    }
};

module.exports = { analyzeCommentsWithAI };